

feature/KIRO-007での対応でかなり無駄なファイルを削除できてClaudeも冗長なコンテキストをシェイプアップできました。

それでもまだユーザーの思ったようにClaudeは動作してくれません

https://zenn.dev/knowledgework/articles/learning-context-engineering
このzennの記事を見てください
ユーザーもこの記事と同じ問題を抱えてます
おそらく「かなりのドキュメント量を読み込ませすぎて**ポイント：情報を増やすだけでは逆効果、整理が必要！**」状態になってます。
現在の強制ワークフローをスルときに読み込ませるコンテキストの量を計算して。
* この記事のの通りに前提条件や渡すコンテキスト量が膨大すぎて、LLMの見落としやすい状態に陥ってないかどうかのファクトチェック
* ファクトチェックの方法はユーザーはどうすればいいかわからないのでClaudeの方でどういう方法が良いかの検討をしてください
* そのチェックをしたあとのまとめをMarkDown形式に落とし込んでほしい
	* 可能な限りにブレイクダウン


