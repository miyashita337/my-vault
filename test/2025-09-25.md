

feature/KIRO-007での対応でかなり無駄なファイルを削除できてClaudeも冗長なコンテキストをシェイプアップできました。

それでもまだユーザーの思ったようにClaudeは動作してくれません

https://zenn.dev/knowledgework/articles/learning-context-engineering
このzennの記事を見てください
ユーザーもこの記事と同じ問題を抱えてます
おそらく「かなりのドキュメント量を読み込ませすぎて**ポイント：情報を増やすだけでは逆効果、整理が必要！**」状態になってます。
現在の強制ワークフローをスルときに読み込ませるコンテキストの量を計算して。
* この記事のの通りに前提条件や渡すコンテキスト量が膨大すぎて、逆にノイズになってLLMの見落としやすい状態に陥ってないかどうかのファクトチェック
* ファクトチェックの方法はユーザーはどうすればいいかわからないのでClaudeの方でどういう方法が良いかの検討をして、提案をしてほしいです
* チェック→調査→結果を出したあとのまとめをMarkDown形式に落とし込んでほしい
* 可能な限りにブレイクダウンして細分化して以下をまとめて
	* 概要
	* 問題
	* 経緯
	* 調査方法
	* 調査結果
	* 原因
	* 根本的な解決方法
	* 
	* 


不明点やヒアリングが必要な場合は実行前に聞き出してほしい
ユーザーが勘違いしている可能性も考慮して、できるだけフラットに観てほしい

